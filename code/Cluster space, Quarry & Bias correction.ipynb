{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35160b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b373af41",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_data= pd.read_csv('input.csv')\n",
    "rainfall_data.dropna(inplace=True)\n",
    "rainfall_data.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7236e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(12, 2, figsize=(15, 90))\n",
    "for hour in range(1,24):\n",
    "    formatted_hour = str(hour).zfill(2)\n",
    "    i= int((hour-1)/2)\n",
    "    j= int((hour-1)%2)\n",
    "    axs[i, j].scatter(rainfall_data['TOTRF'],rainfall_data['HRF'+formatted_hour])\n",
    "    axs[i, j].set_title('HRF'+formatted_hour)\n",
    "    hour= hour+1\n",
    "plt.subplots_adjust(hspace=0.5,wspace=0.3) \n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb80d0",
   "metadata": {},
   "source": [
    "# clustering algorithym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0414212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_clustering(data_frame,hour,epoch= 3,limit= 30):\n",
    "    if hour== 25:\n",
    "        scaler = MinMaxScaler()\n",
    "        a=scaler.fit_transform(data_frame.iloc[:,[-1]])\n",
    "\n",
    "        km=KMeans(n_clusters=1,n_init=10, init='k-means++')\n",
    "        km.fit(a)\n",
    "        x_first= km.inertia_\n",
    "        old_x_first= 0\n",
    "    \n",
    "        km=KMeans(n_clusters=limit,n_init=10, init='k-means++')\n",
    "        km.fit(a)\n",
    "        x_last= km.inertia_\n",
    "        old_x_last= 0\n",
    "    \n",
    "        k= 1\n",
    "        flag= 1\n",
    "        array= np.zeros((epoch,2),dtype= float)\n",
    "        for i in range(epoch) :\n",
    "            old_x_first= x_first\n",
    "            old_x_last = x_last\n",
    "            k = k+1\n",
    "            km=KMeans(n_clusters=k,n_init=10, init='k-means++')\n",
    "            km.fit(a)\n",
    "            x_first= km.inertia_\n",
    "            km=KMeans(n_clusters=limit-(k-1),n_init=10, init='k-means++')\n",
    "            km.fit(a)\n",
    "            x_last= km.inertia_          \n",
    "            nr        = ((x_last-x_first)+(x_first-old_x_first)*k-(x_last-old_x_last)*(limit-(k-1)))\n",
    "            dr        = ((x_first-old_x_first)-(x_last-old_x_last))\n",
    "            array[i,0]= nr/dr\n",
    "            array[i,1]= (x_first-old_x_first)*((nr/dr)-k)+x_first\n",
    "        \n",
    "        reg= linear_model.LinearRegression()    \n",
    "        reg.fit(array[:, 0].reshape(-1, 1), array[:, 1])\n",
    "    \n",
    "        min_cluster= 1\n",
    "        k= (min_cluster+limit)/2\n",
    "        k= int(k)\n",
    "        while min_cluster<limit:\n",
    "            km=KMeans(n_clusters=k,n_init=10, init='k-means++')\n",
    "            km.fit(a)\n",
    "            if reg.predict(np.array([[k]]))>km.inertia_:\n",
    "                limit= k-1\n",
    "            if reg.predict(np.array([[k]]))<km.inertia_:\n",
    "                min_cluster= k+1\n",
    "            else:\n",
    "                index= k\n",
    "            k= int((min_cluster+limit)/2)\n",
    "        index= k\n",
    "        \n",
    "        km = KMeans(n_clusters=index,n_init=10, init='k-means++')\n",
    "        s  = km.fit_predict(a)\n",
    "        q  = km.cluster_centers_\n",
    "    \n",
    "        data_frame['cluster']=s\n",
    "        data_frame['TOTRF']=q[data_frame['cluster'],0]\n",
    "        data_frame.drop(columns=['cluster'],inplace= True)\n",
    "        data_frame['TOTRF']= scaler.inverse_transform(data_frame.iloc[:,[-1]])[:,0]\n",
    "        \n",
    "        return data_frame\n",
    "    \n",
    "    #plt.scatter(data_frame.iloc[:,-2],data_frame.iloc[:,-1])\n",
    "    scaler = MinMaxScaler()\n",
    "    a=scaler.fit_transform(data_frame.iloc[:,[-1,hour-1]])\n",
    "    \n",
    "    km=KMeans(n_clusters=1,n_init=10, init='k-means++')\n",
    "    km.fit(a)\n",
    "    x_first= km.inertia_\n",
    "    old_x_first= 0\n",
    "    \n",
    "    km=KMeans(n_clusters=limit,n_init=10, init='k-means++')\n",
    "    km.fit(a)\n",
    "    x_last= km.inertia_\n",
    "    old_x_last= 0\n",
    "    \n",
    "    k= 1\n",
    "    flag= 1\n",
    "    array= np.zeros((epoch,2),dtype= float)\n",
    "    for i in range(epoch) :\n",
    "        old_x_first= x_first\n",
    "        old_x_last = x_last\n",
    "        k = k+1\n",
    "        km=KMeans(n_clusters=k,n_init=10, init='k-means++')\n",
    "        km.fit(a)\n",
    "        x_first= km.inertia_\n",
    "        km=KMeans(n_clusters=limit-(k-1),n_init=10, init='k-means++')\n",
    "        km.fit(a)\n",
    "        x_last= km.inertia_          \n",
    "        nr        = ((x_last-x_first)+(x_first-old_x_first)*k-(x_last-old_x_last)*(limit-(k-1)))\n",
    "        dr        = ((x_first-old_x_first)-(x_last-old_x_last))\n",
    "        array[i,0]= nr/dr\n",
    "        array[i,1]= (x_first-old_x_first)*((nr/dr)-k)+x_first\n",
    "        \n",
    "    reg= linear_model.LinearRegression()    \n",
    "    reg.fit(array[:, 0].reshape(-1, 1), array[:, 1])\n",
    "    \n",
    "    min_cluster= 1\n",
    "    k= (min_cluster+limit)/2\n",
    "    k= int(k)\n",
    "    while min_cluster<limit:\n",
    "        km=KMeans(n_clusters=k,n_init=10, init='k-means++')\n",
    "        km.fit(a)\n",
    "        if reg.predict(np.array([[k]]))>km.inertia_:\n",
    "            limit= k-1\n",
    "        if reg.predict(np.array([[k]]))<km.inertia_:\n",
    "            min_cluster= k+1\n",
    "        else:\n",
    "            index= k    \n",
    "        k= int((min_cluster+limit)/2)\n",
    "    index= k\n",
    "    \n",
    "    print('index for hour',hour,'is',index)\n",
    "    km = KMeans(n_clusters=index,n_init=10, init='k-means++')\n",
    "    s  = km.fit_predict(a)\n",
    "    q  = km.cluster_centers_\n",
    "    data_frame['cluster']=s\n",
    "    formatted_hour = str(hour).zfill(2)\n",
    "    data_frame['HRF'+formatted_hour]=q[data_frame['cluster'],1]\n",
    "    \n",
    "    data_frame.drop(columns=['cluster'],inplace= True)\n",
    "    data_frame['HRF'+formatted_hour]= scaler.inverse_transform(data_frame.iloc[:,[-1,hour-1]])[:,1]\n",
    "                                                                                  \n",
    "    i= int((hour-1)/2)\n",
    "    j= int((hour-1)%2)\n",
    "    axs[i, j].scatter(data_frame['TOTRF'],data_frame['HRF'+formatted_hour],c=s, cmap='tab10')\n",
    "    axs[i, j].set_title('HRF'+formatted_hour)\n",
    "    \n",
    "    return do_clustering(data_frame,hour+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f54dbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = rainfall_data.drop(columns=['INDEX', 'YEAR', 'MN', 'DT', 'DAY', 'TOT_Cal'])\n",
    "df = df[df['TOTRF'] != 0]\n",
    "fig, axs = plt.subplots(12,2, figsize=(15,90))\n",
    "result = do_clustering(df,1)\n",
    "plt.subplots_adjust(hspace=0.5,wspace=0.3) \n",
    "plt.tight_layout()\n",
    "plt.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4564797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result # THE CLUSTER SPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037502e",
   "metadata": {},
   "source": [
    "# the quarry algorithym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92007ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Season' in rainfall_data.columns:\n",
    "    rainfall_data.drop(columns=['Season'], inplace=True)\n",
    "    result.drop(columns=['Season'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e333fbe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "season_mapping = {\n",
    "    1: 1, 2: 1, 3: 2,\n",
    "    4: 2, 5: 2, 6: 3,\n",
    "    7: 3, 8: 3, 9: 3,\n",
    "    10: 4, 11: 4, 12: 4\n",
    "}\n",
    "rainfall_data['Season'] = rainfall_data['MN'].map(season_mapping)\n",
    "a= rainfall_data[rainfall_data['TOTRF']!=0]['Season']\n",
    "result['Season']=a\n",
    "result.reset_index(drop=True,inplace=True)\n",
    "\n",
    "trf= float(input('Enter the total rainfall: '))\n",
    "season= float(input('Enter the season: '))\n",
    "\n",
    "b = (result['TOTRF'] - trf) ** 2\n",
    "array = result.iloc[b[b == b.min()].index]\n",
    "array = array[array['Season']==season]\n",
    "array.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fig, axs = plt.subplots(int((len(array)/5)+1),5, figsize=(20,4*int((len(array)/5)+1)))\n",
    "for index,row in array.iterrows():\n",
    "    i= int(index/5)\n",
    "    j= int(index%5)\n",
    "    axs[i,j].plot(range(len(row.values)-2),row.values[:-2])\n",
    "    cumulative= row.values[:-2].cumsum()\n",
    "    axs[i,j].plot(range(len(row.values)-2),cumulative)\n",
    "    axs[i, j].set_title('Index:'+str(index))\n",
    "plt.subplots_adjust(hspace=0.5,wspace=0.3) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258174a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "array # THE QUARRY DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3f551",
   "metadata": {},
   "source": [
    "# bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(array: np.ndarray, value: float) -> float:\n",
    "    return (np.sum(array)- value)**2\n",
    "\n",
    "def seasonal_line(array: np.ndarray, reference: pd.DataFrame) -> Tuple[float, np.ndarray]:\n",
    "    a = reference.values\n",
    "    b = np.tile(array, (a.shape[0], 1))\n",
    "    dot_products = np.sum(a * b, axis=1)\n",
    "    norms_a = np.linalg.norm(a, axis=1)\n",
    "    norms_b = np.linalg.norm(b, axis=1)\n",
    "    cosine_similarities = dot_products / (norms_a * norms_b)\n",
    "    cosine_similarities = np.nan_to_num(cosine_similarities, nan=0.0)\n",
    "    fs = np.max(cosine_similarities)\n",
    "    p = a[np.argmax(cosine_similarities)]\n",
    "    p_mod = norms_a[np.argmax(cosine_similarities)]\n",
    "    v_mod = norms_b[np.argmax(cosine_similarities)]\n",
    "    del_fs = (p / p_mod * v_mod) - (fs * array)\n",
    "    return fs, del_fs\n",
    "\n",
    "def forward_pass(input_: np.ndarray, weights: np.ndarray, reference: pd.DataFrame, trf: float) -> Tuple[np.ndarray, float, np.ndarray, np.ndarray, float]:\n",
    "    op_1 = input_ * weights\n",
    "    fs, del_fs = seasonal_line(op_1, reference)\n",
    "    op_2 = np.abs(op_1 * fs)\n",
    "    error = mse(op_2, trf)\n",
    "    return op_1, fs, del_fs, op_2, error\n",
    "\n",
    "def backward_pass(input_: np.ndarray, op_1: np.ndarray, fs: float, del_fs: np.ndarray, op_2: np.ndarray, error: float) -> np.ndarray:\n",
    "    del_wt = (2 * np.sqrt(error) * (fs + (np.sum(op_1) * del_fs))) * input_\n",
    "    return del_wt\n",
    "\n",
    "def parameter_upgrade(weights: np.ndarray, del_wt: np.ndarray, op_2: np.ndarray, trf: float, alpha: float) -> np.ndarray:\n",
    "    if (np.sum(op_2) - trf) > 0:\n",
    "        weights = weights - alpha * del_wt\n",
    "    else:\n",
    "        weights = weights + alpha * del_wt\n",
    "    return weights\n",
    "\n",
    "def Bias_correction(input_: np.ndarray, reference: pd.DataFrame, trf: float, epochs: int = 50, alpha: float = 0.08) -> np.ndarray:\n",
    "    weights = np.ones_like(input_)\n",
    "    error_list: List[float] = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        op_1, fs, del_fs, op_2, error = forward_pass(input_, weights, reference, trf)\n",
    "        del_wt = backward_pass(input_, op_1, fs, del_fs, op_2, error)\n",
    "        weights = parameter_upgrade(weights, del_wt, op_2, trf, alpha)\n",
    "        error_list.append(error)\n",
    "    \n",
    "    plt.plot(range(len(error_list)), error_list, label=\"Error\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return op_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e254bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "index= int(input(\"Enter the index: \"))\n",
    "\n",
    "df= array.drop(columns=['TOTRF','Season'])\n",
    "df['TOTRF']= np.sum(df.values[:,:],axis=1)\n",
    "reference = df.copy(deep= True)\n",
    "\n",
    "reference['TOTRF']= np.sum(reference.values[:,:],axis=1)\n",
    "scalar    = reference.max().max()\n",
    "reference = reference/scalar\n",
    "scaled_trf= trf/scalar\n",
    "reference.drop(columns=['TOTRF'],inplace=True)\n",
    "\n",
    "output= Bias_correction(reference.iloc[index,:].values,reference,scaled_trf)\n",
    "output= np.append(output,np.sum(output))\n",
    "output= output*(trf/output[-1])\n",
    "\n",
    "plt.plot(range(len(df.iloc[index,:].values)), df.iloc[index,:].values, label='Input series')\n",
    "plt.plot(range(len(output)),output,label='Output series')\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Rainfall\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reference.iloc[index,:].values) # the input of bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output) # the output of bias correction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
